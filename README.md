
# ğŸ§ Palmer Penguins EDA ë¦¬í¬íŠ¸ (ìƒê´€ê³„ìˆ˜ í¬í•¨)

## 01. í”„ë¡œì íŠ¸ ê°œìš”
- **ë¶„ì„ ëª©ì **: í­ê·„ì˜ ë‹¤ì–‘í•œ ìƒë¬¼í•™ì  íŠ¹ì„±(ë¶€ë¦¬ ê¸¸ì´, ë‚ ê°œ ê¸¸ì´ ë“±)ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…(species)ì„ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
- **ë°ì´í„° ì¶œì²˜**: Palmer Penguins ë°ì´í„°ì…‹ (https://allisonhorst.github.io/palmerpenguins/)
- **ë°ì´í„° êµ¬ì„±**: 8ê°œì˜ ì£¼ìš” íŠ¹ì„±ê³¼ ì¢…(species), ì„±ë³„(sex), ì„œì‹ì§€(island) ë“±ìœ¼ë¡œ êµ¬ì„±ëœ ì´ 344ê°œ ìƒ˜í”Œ
- **ë¶„ì„ ë‹¨ìœ„**: ê°œë³„ í­ê·„

---

## 02. ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ êµ¬ì¡° í™•ì¸

```python
import pandas as pd
df = pd.read_csv("penguins.csv")
print(df.info())
print(df.head())
print(df.shape)
```

---

## 03. ë°ì´í„° ìš”ì•½ ë° ê¸°ìˆ  í†µê³„

```python
print(df.describe())
print(df['species'].value_counts())
```

- ìˆ˜ì¹˜í˜• ë³€ìˆ˜(bill_length_mm, flipper_length_mm ë“±)ì˜ ê¸°ë³¸ í†µê³„ í™•ì¸
- ì¢…ë³„(species) ë¶„í¬ëŠ” Adelie > Gentoo > Chinstrap ìˆœìœ¼ë¡œ ë¶ˆê· í˜•í•¨

---

## 04. ë°ì´í„° í´ë Œì§• & ì „ì²˜ë¦¬ (Data Cleaning & Preprocessing)

- ê²°ì¸¡ì¹˜ ì œê±° (NA í–‰ ì‚­ì œ)
- ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”© (sex, island)
- ì¢…(Species) ë³€ìˆ˜ëŠ” ë¼ë²¨ ì¸ì½”ë”©ìœ¼ë¡œ ìˆ«ìë¡œ ë³€í™˜
- ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (StandardScaler ì‚¬ìš©)

```python
# ê²°ì¸¡ì¹˜ ì œê±°
df = df.dropna()

# ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©
df = pd.get_dummies(df, columns=["sex", "island"])

# ì¢…(species) ë¼ë²¨ ì¸ì½”ë”©
from sklearn.preprocessing import LabelEncoder
LE = LabelEncoder()
df["species"] = LE.fit_transform(df["species"])
```

```python
print(df.isnull().sum())
df = df.dropna()
```

- sex, body_mass_g ë“±ì— ê²°ì¸¡ì¹˜ ì¡´ì¬
- ì „ì²´ ìƒ˜í”Œ ìˆ˜ê°€ ë§ì§€ ì•Šì•„ ê²°ì¸¡ì¹˜ í–‰ ì œê±° ì²˜ë¦¬
```

---

## 05. ë³€ìˆ˜ ë¶„í¬ ì‹œê°í™”

```python
import seaborn as sns
import matplotlib.pyplot as plt

num_features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']

for col in num_features:
    sns.histplot(data=df, x=col, kde=True)
    plt.title(f"{col} ë¶„í¬")
    plt.show()
```

- flipper_length_mm, body_mass_g ë“±ì€ ì •ê·œ ë¶„í¬ í˜•íƒœ
- bill_depth_mm ë“±ì€ ì¢…ë³„ë¡œ êµ°ì§‘ëœ ë¶„í¬

---

## 06. ë³€ìˆ˜ë³„ ì´ìƒì¹˜ í™•ì¸

```python
for col in num_features:
    sns.boxplot(data=df, y=col)
    plt.title(f"{col} ì´ìƒì¹˜")
    plt.show()
```

- ì¼ë¶€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì—ì„œ ì´ìƒê°’ ì¡´ì¬í•˜ë‚˜ í° ì˜í–¥ì€ ì—†ìŒ

---

## 07. ì´ì‚°ê°’ì— ë”°ë¥¸ ì—°ì†ê°’ ì‹œê°í™”

```python
for col in num_features:
    sns.boxplot(data=df, x='species', y=col)
    plt.title(f"speciesë³„ {col} ë¶„í¬")
    plt.show()
```

- ì¢…ë³„ë¡œ ì²´ì¤‘(body_mass_g), ë¶€ë¦¬ ê¸¸ì´(bill_length_mm), ë‚ ê°œ ê¸¸ì´(flipper_length_mm) ë“±ì´ ìœ ì˜í•œ ì°¨ì´ë¥¼ ë³´ì„

---

## 08. ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì‹œê°í™” ë° í•´ì„

```python
corr = df.corr(numeric_only=True)
sns.heatmap(corr, annot=True)
plt.show()
```

- `flipper_length_mm`ì™€ `body_mass_g`ëŠ” **ìƒê´€ê³„ìˆ˜ 0.87**ë¡œ ë§¤ìš° ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„
- `bill_length_mm`ì™€ `bill_depth_mm`ì€ **ìƒê´€ê³„ìˆ˜ -0.23**ìœ¼ë¡œ ì•½í•œ ìŒì˜ ìƒê´€ê´€ê³„
- `bill_length_mm`ì™€ `flipper_length_mm`ë„ **0.65**ë¡œ ë†’ì€ ì–‘ì˜ ìƒê´€ê´€ê³„

---

## 09. Feature Engineering

- ì¢…ì„ êµ¬ë¶„ì§“ëŠ” íŠ¹ì„±ì„ ì‹œê°í™”ë¡œ ë¶„ì„í•˜ê³ , ëª¨ë¸ì— íˆ¬ì…í•  feature ì„ íƒ
```python
sns.pairplot(df, hue='species')
```

- flipper_length_mm, bill_length_mm, body_mass_g ì¡°í•©ìœ¼ë¡œ ì¢…ë³„ ê²½ê³„ê°€ ë¹„êµì  ëšœë ·

---

## 10. ìµœì¢… ìš”ì•½ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

- Adelie, Gentoo, Chinstrap í­ê·„ì€ ìƒë¬¼í•™ì  íŠ¹ì„±ì—ì„œ í™•ì‹¤í•œ ì°¨ì´ë¥¼ ë³´ì„
- ì£¼ìš” ìƒê´€ê´€ê³„ ìˆ˜ì¹˜ ìš”ì•½:
  - `flipper_length_mm` â†” `body_mass_g`: **0.87**
  - `bill_length_mm` â†” `body_mass_g`: **0.60**
  - `bill_length_mm` â†” `flipper_length_mm`: **0.65**
  - `bill_length_mm` â†” `bill_depth_mm`: **-0.23**

- ë¶€ë¦¬ ê¸¸ì´, ì²´ì¤‘, ë‚ ê°œ ê¸¸ì´ëŠ” ì¢… ë¶„ë¥˜ì— ê°€ì¥ ì¤‘ìš”í•œ ë³€ìˆ˜ë¡œ í™œìš© ê°€ëŠ¥
- ê°„ë‹¨í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œë„ ë†’ì€ ì •í™•ë„ë¡œ ì¢… ë¶„ë¥˜ ê°€ëŠ¥í•¨

## 11. ë¨¸ì‹ ëŸ¬ë‹ - í­ê·„ì˜ ì¢… ë¶„ë¥˜ ì˜ˆì¸¡ (Logistic Regression)

í­ê·„ì˜ ì‹ ì²´ íŠ¹ì§•(ë¶€ë¦¬ ê¸¸ì´, ê¹Šì´, ë‚ ê°œ ê¸¸ì´, ëª¸ë¬´ê²Œ ë“±)ì„ ê¸°ë°˜ìœ¼ë¡œ `species(ì¢…)`ì„ ì˜ˆì¸¡í•˜ëŠ” ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•œë‹¤. Logistic Regressionì„ í™œìš©í•œ ë‹¤ì¤‘ ë¶„ë¥˜ ì‘ì—…ì„ ì§„í–‰í•˜ë©°, ì „ì²˜ë¦¬ë¡œëŠ” í‘œì¤€í™”ì™€ ê²°ì¸¡ì¹˜ ë³´ì •ì„ í¬í•¨í•œë‹¤.

~~ Featureì™€ Target ì •ì˜
```python
X = df.drop("species", axis=1)
y = df["species"]
```

~~ Train/Test ë¶„í•  (Stratified Sampling ì‚¬ìš©)
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```

~~ í‘œì¤€í™” (StandardScaler ì‚¬ìš©)
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)  # âš ï¸ ì‹¤ì œë¡œëŠ” transformë§Œ ì ìš©í•˜ëŠ” ê²ƒì´ ì ì ˆ

X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)
```

~~ ê²°ì¸¡ì¹˜ ë³´ì • (KNNImputer ì‚¬ìš©)
```python
from sklearn.impute import KNNImputer

knn_imputer = KNNImputer(n_neighbors=2, weights="uniform")
X_train[:] = knn_imputer.fit_transform(X_train)
X_test[:] = knn_imputer.fit_transform(X_test)
```

~~ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

LogReg = LogisticRegression()
LogReg.fit(X_train, y_train)

y_pred = LogReg.predict(X_test)

print("ì •í™•ë„:", accuracy_score(y_test, y_pred))
print("í…ŒìŠ¤íŠ¸ ì ìˆ˜:", LogReg.score(X_test, y_test))
print(classification_report(y_test, y_pred))
```

- ë¶„ë¥˜ ëª¨ë¸: **Logistic Regression**
- ì •í™•ë„: `ì•½ XX%` (ì‹¤í–‰ ê²°ê³¼ë¡œ ê¸°ì…)
- ë¶„ë¥˜ ë¦¬í¬íŠ¸: precision, recall, f1-scoreë¥¼ í†µí•´ ê° ì¢…ë³„ ë¶„ë¥˜ ì„±ëŠ¥ í™•ì¸

